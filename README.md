Below is a collection of resources for learning how to work with and develop Artificial Intelligence and Machine Learning (AIML) systems. I’ve also included some resources that target the general software engineering community.

# Books

## AIML Books

* The Hundred-Page Machine Learning Book - Andriy Burkov: https://a.co/d/eoqYeyZ
  * Overview of ML principles and algorithms
* The Hundred-Page Language Models Book - Andriy Burkov: https://a.co/d/6cqSZQR
  * Master language models through mathematics, illustrations, code, and build your own from scratch
* Machine Learning Engineering - Andriy Burkov: https://a.co/d/cHDNMnq
  * Best practices and design patterns of building reliable machine learning solutions that scale
* Designing Machine Learning Systems -  Chip Huyen: https://a.co/d/7ywG2ei
  * ML system design tradeoffs
* AI Engineering: Building Applications with Foundation Models - Chip Huyen: https://a.co/d/24ZnAY8
  * Model serving & product constraints.
* Building LLMs for Production - Bouchard & Peters: https://a.co/d/c5XEWvB
  * Real-world LLM deployment.
* Build a LLM (From Scratch) - Sebastian Raschka: https://a.co/d/6CbKcY1
  * Understanding LLM internals.
* The LLM Engineering Handbook – Iusztin & Labonne: https://a.co/d/d6CiXE5
  * Modular, scalable GenAI systems
* Deep Reinforcement Learning Hands-On - Maxim Lapan: https://a.co/d/fd0xQfw
  * A practical and easy-to-follow guide to RL from Q-learning and DQNs to PPO and RLHF
* LLMs in Production: From language models to successful products – Brousseau and Sharp: https://a.co/d/8Yv65ec
  * Goes beyond academic discussions deeply into the applications layer of Foundation Models.
* Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow - Aurélien Géron: https://a.co/d/3eJQ2bf
  * Concepts, Tools, and Techniques to Build Intelligent Systems
* Hands-On Machine Learning with C++ - Kirill Kolodiazhnyi: https://a.co/d/3hdLE2c
  * Build, train, and deploy end-to-end machine learning and deep learning pipelines
* Deep Learning: https://www.deeplearningbook.org/
  * Resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular

## Foundational Mathematics

* Mathematics for Machine Learning: https://mml-book.github.io/
  * Provides necessary mathematical skills to understand modern machine learning techniques
* An Introduction to Statistical Learning: https://www.statlearning.com/
  * Provides a broad and less technical treatment of key topics in statistical learning

## Data Engineering Books

* Designing Data-Intensive Applications – Martin Kleppmann: https://a.co/d/jaKFbTy
  * The Big Ideas Behind Reliable, Scalable, and Maintainable Systems
  * https://newsletter.techworld-with-milan.com/p/what-i-learned-from-the-book-designing

## Software Engineering Books

* The DevOps Handbook, 2nd Edition: How to Create World-Class Agility, Reliability, & Security in Technology Organizations – Gene Kim: https://a.co/d/fgb5o19
  * Fantastic in-depth knowledge of IT development best practices to survive global competition
* Clean Code – Robert Martin: https://a.co/d/ebzbOWu
  * A Handbook of Agile Software Craftsmanship
* Clean Architecture – Robert Martin: https://a.co/d/5lexOZH
  * A Craftsman's Guide to Software Structure and Design
* The Pragmatic Programmer – Andrew Hunt: https://a.co/d/36huLs4
  * Best practices and major pitfalls of many different aspects of software development
* Effective C++ - Scott Meyers: https://a.co/d/0xpXAF4
  * 55 Specific Ways to Improve Your Programs and Designs
* Effective Modern C++ - Scott Meyers: https://a.co/d/aBPyMaU
  * 42 Specific Ways to Improve Your Use of C++11 and C++14
* Code Complete (2nd edition) – Steve McConnell: https://a.co/d/1rd0NmE
  * A Practical Handbook of Software Construction
* Software Engineering at Google – Titus Winters: https://a.co/d/iVLdJ8I
  * Lessons Learned from Programming Over Time

## Software Interview Prep:

* System Design Interview (Vol 1) - Alex Xu: https://a.co/d/h1rjGHV
* System Design Interview (Vol 2) - Alex Xu: https://a.co/d/6LeVmL6
* Machine Learning System Design Interview - Alex Xu: https://a.co/d/balA6ca
* Generative AI System Design Interview – Ali Aminian: https://a.co/d/az1jUBy

# Papers

* Attention Is All You Need: https://arxiv.org/abs/1706.03762
* Proximal Policy Optimization Algorithms: https://arxiv.org/abs/1707.06347
* Self Adapting Language Models: https://arxiv.org/html/2506.10943v1
* OpenAI GPT-4 Technical Report: https://arxiv.org/abs/2303.08774
* Google Gemini: A Family of Highly Capable Multimodal Models: https://arxiv.org/abs/2312.11805
* DeepSeek-R1: https://arxiv.org/abs/2501.12948

# Publications

* Trends – Artificial Intelligence – Mary Meeker – May 2025: https://www.bondcap.com/report/pdf/Trends_Artificial_Intelligence.pdf

# Educational

## Videos

* Intro to Large Language Models by Andrej Karpathy: https://www.youtube.com/watch?v=zjkBMFhNj_g
* Deep Dive into LLMs like ChatGPT by Andrej Karpathy: https://www.youtube.com/watch?v=7xTGNNLPyMI
* How Andrej Karpathy Uses LLMs: https://www.youtube.com/watch?v=EWvNQjAaOHw
* Neural Networks: Zero to Hero by Andrej Karpathy: https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&si=9yCI-WiAqFOGglpe
* Stanford CS229 - Machine Learning - Introduction - 2022 - Lecture 1: https://youtu.be/Bl4Feh_Mjvo?si=oEGFrwP4cVmzwq4u
* Stanford CS229 - Machine Learning - Building Large Language Models - 2023: https://www.youtube.com/watch?v=9vM4p9NN0Ts
* Stanford CS336 Language Modeling From Scratch: https://youtube.com/playlist?list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_&si=8_UAIgw31qq2revf
* Stanford CS25: V2 I Introduction to Transformers w/ Andrej Karpathy: https://www.youtube.com/watch?v=XfpMkf4rD6E
* MIT Introduction to Deep Learning – 2024: https://youtu.be/ErnWZxJovaM?si=hHH3I8-1ZXfTJse7
* Your Guide to Generative AI Courses: https://www.deeplearning.ai/resources/generative-ai-courses-guide/
* Let's build GPT: from scratch, in code, spelled out: Andrej Karpathy: https://www.youtube.com/watch?v=kCc8FmEb1nY
* Building LLMs from the Ground Up: A 3-hour Coding Workshop - Sebastian Raschka, 2024: https://www.youtube.com/watch?v=quh7z1q7-uc
* Deep Learning for Computer Vision with Python and TensorFlow: https://www.youtube.com/watch?v=IA3WxTTPXqQ
* 22 Machine Learning Projects That Will Make You A God At Data Science: https://www.youtube.com/watch?v=QlbyGPVaRSE

## Courses

* Machine Learning Crash Course: https://developers.google.com/machine-learning/crash-course
  * Google's fast-paced, practical introduction to machine learning, featuring a series of animated videos, interactive visualizations, and hands-on practice exercises
* Machine Learning Specialization: https://www.coursera.org/specializations/machine-learning-introduction
  * It's long, but feel free to skip lectures if you’ve heard or understood the concepts. This specialization is the common get-started point for getting into Machine Learning
* Google and Kaggle’s free GenAI Intensive course: https://www.youtube.com/watch?v=kCc8FmEb1nY
  * Foundational Models & Prompt Engineering, Embeddings and Vector Stores/Databases, Generative AI Agents, Domain-Specific LLMs, MLOps for Generative AI
* Anthropic Academy: https://www.anthropic.com/learn
  * Official Claude dev hub — APIs, safety, workflows
* Microsoft AI Learning Hub: https://learn.microsoft.com/en-us/ai/?tabs=developer
  * Full-stack GenAI learning with Azure tools
* NVIDIA GenAI/LLM Learning Paths: https://www.nvidia.com/en-us/learn/learning-path/generative-ai-llm/
  * Build, tune, deploy — all in one place
* DeepLearning AI: https://www.deeplearning.ai/
  * Short, practical GenAI and RAG courses
* Master Production AI With End-to-End Open-Source Courses: https://decodingml.substack.com/p/master-production-ai-with-our-end
  * If you thrive on hands-on experiences and building projects, these courses are for you.
* TensorFlow Certificates:
  * https://www.tensorflow.org/certificate
  * https://www.coursera.org/professional-certificates/tensorflow-in-practice
  * https://github.com/https-deeplearning-ai/tensorflow-1-public
  * https://github.com/https-deeplearning-ai/tensorflow-2-public
  * https://github.com/https-deeplearning-ai/tensorflow-3-public
* edX Data Engineering: https://www.edx.org/learn/data-engineering
* edX Deep Learning: https://www.edx.org/learn/deep-learning
* edX Machine Learning: https://www.edx.org/learn/machine-learning
* AWS Skill Builder: https://skillbuilder.aws/
  * Build in-demand cloud and AI skills for yourself and your team. Offers free and low-cost AI courses and learning resources
* Google AI Courses: https://grow.google/ai/
  * In-demand AI courses for today's workforce
* Google Learn Essential AI Skills: https://ai.google/learn-ai-skills/

## Prompting

* Prompt Engineering by OpenAI: https://platform.openai.com/docs/guides/text?api-mode=responses
* Related resources from around the web: https://cookbook.openai.com/articles/related_resources
* Prompting Guide: https://www.promptingguide.ai/introduction
* ChatGPT Prompt Engineering for Developers: https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/

## Tools

* Google Colab: https://colab.google/
  * Colab is a hosted Jupyter Notebook service that requires no setup to use and provides free access to computing resources, including GPUs and TPUs. Colab is especially well suited to machine learning, data science, and education.
* NotebookLM: https://notebooklm.google/
  * A free AI tool for research and learning from documents, allowing users to upload PDFs, slides, and articles for summarization, quote extraction, and Q&A with citations
 
## Repositories

* Andrej Karpathy - Neural Networks: Zero to Hero: https://github.com/karpathy/nn-zero-to-hero
* Start Machine Learning by Louis-François Bouchard: https://github.com/louisfb01/start-machine-learning
* fastai: https://github.com/fastai/fastai
* RAG Techniques – Nir Diamant: https://github.com/NirDiamant/RAG_Techniques
* GenAI Agents – Nir Diamant: https://github.com/NirDiamant/GenAI_Agents
* system-prompts-and-models-of-ai-tools: https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools
  * A collection of prompts for various

# Communities

* https://huggingface.co/
* https://www.kaggle.com/
  * https://www.kaggle.com/learn
* https://www.reddit.com/r/aiml/
* https://www.reddit.com/r/LLM/

# Blogs

* https://www.interconnects.ai/
* https://codingwithintelligence.com/
* https://frontierai.substack.com/
* https://aiagentssimplified.substack.com/
* https://www.deeplearningweekly.com/
* https://vladbogo.substack.com/
* https://importai.substack.com/
* https://www.pragmaticengineer.com/
* https://theneuralmaze.substack.com/
* https://multimodalai.substack.com/
* https://www.ai-supremacy.com/
* https://decodingml.substack.com/
* https://blog.neosage.io/
* https://towardsdatascience.com/

# Articles

* From 0 to Pro AI Engineering Roadmap: https://decodingml.substack.com/p/from-0-to-pro-ai-engineering-roadmap
* Basic facts about GPUs: https://damek.github.io/random/basic-facts-about-gpus/
* The AI/ML Engineer's starter guide to GPU Programming: https://multimodalai.substack.com/p/the-mlai-engineers-starter-guide
* Understanding LLM Inference: https://multimodalai.substack.com/p/understanding-llm-inference
* Understanding and Coding the KV Cache in LLMs from Scratch: https://magazine.sebastianraschka.com/p/coding-the-kv-cache-in-llms
* How to Fine-Tune Small Language Models to Think with Reinforcement Learning: https://towardsdatascience.com/how-to-finetune-small-language-models-to-think-with-reinforcement-learning/
* Context Kills VRAM: How to Run LLMs on consumer GPUs: https://medium.com/@lyx_62906/context-kills-vram-how-to-run-llms-on-consumer-gpus-a785e8035632
* Let’s talk about the PyTorch dispatcher: https://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/
* How to deploy an LLM server yourself: https://paulabartabajo.substack.com/p/how-to-deploy-an-llm-server-yourself
* The Generative AI Stack: https://blog.bytebytego.com/p/ep171-the-generative-ai-tech-stack
* Agentic AI: Implementing Long-Term Memory: https://towardsdatascience.com/agentic-ai-implementing-long-term-memory/
* Grow as an AI Engineer – Past the surface level: https://multimodalai.substack.com/p/grow-as-an-ai-engineer-past-the-surface
* Hands-On Attention Mechanism for Time Series Classification, with Python: https://towardsdatascience.com/hands-on-attention-mechanism-for-time-series-classification-with-python/
* How To Significantly Enhance LLMs by Leveraging Context Engineering: https://towardsdatascience.com/how-to-significantly-enhance-llms-by-leveraging-context-engineering-2/
* How to Ensure Reliability in LLM Applications: https://towardsdatascience.com/how-to-ensure-reliability-in-llm-applications/
* Context Rot: How Increasing Input Tokens Impacts LLM Performance: https://research.trychroma.com/context-rot
* The Open Source Project That Became an Essential Library for Modern AI Engineering: https://medium.com/@lucknitelol/the-open-source-project-that-became-an-essential-library-for-modern-ai-engineering-67021b50acee

# Development

## Software Development

* Ollama: https://ollama.com/
  * Ollama is an open-source platform that simplifies running large language models (LLMs) locally on your computer. It allows you to download and execute various LLMs directly on your machine, offering privacy, customization, and offline usage. Ollama acts as a user-friendly interface and provides an API layer for interacting with these models. 
* Llama.cpp: https://github.com/ggml-org/llama.cpp
  * Inference of Meta's LLaMA model (and others) in pure C/C++
* LLamafile: https://builders.mozilla.org/project/llamafile/
  * Makes running LLMs easier by combining Llama.cpp with other libraries into single executable files, simplifying distribution and deployment.
* LlamaIndex: https://www.llamaindex.ai/
  * LlamaIndex is a data framework focused on helping developers build applications using large language models (LLMs). It provides tools for ingesting, structuring, and retrieving data, as well as integrating with various application frameworks. Essentially, it acts as a bridge between your data and LLMs, making it easier to build applications that can access and utilize your information. 
* Text generation web UI: https://github.com/oobabooga/text-generation-webui
  * A web-based interface for running and interacting with local LLMs, supporting multiple model backends and featuring an extensions ecosystem.
* LocalAI: https://localai.io/
  * The free, OpenAI, Anthropic alternative. Your All-in-One Complete AI Stack - Run powerful language models, autonomous agents, and document intelligence locally on your hardware. No cloud, no limits, no compromise. Open Source MIT Licensed.
* LangChain: https://www.langchain.com/
  * LangChain is an open-source framework designed to simplify the development of applications powered by language models. It provides a standardized way to connect language models to various data sources and other tools, enabling developers to build more sophisticated and versatile AI applications. LangChain focuses on modularity, allowing developers to mix and match components to create custom workflows. 
* vLLM: https://docs.vllm.ai/en/latest/
  * vLLM is a high-throughput and memory-efficient inference engine for large language models (LLMs). It was originally developed at UC Berkeley and has since become a community-driven open-source project. vLLM is designed to address the challenges of running large LLMs by optimizing for throughput, memory usage, and ease of use. 
* system-prompts-and-models-of-ai-tools: https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools
  * A collection of prompts for various AI tools and applications
* Apache Spark: https://spark.apache.org/
  * Apache Spark is an open-source, unified analytics engine for large-scale data processing. It's a fast and general-purpose cluster-computing system designed for handling massive datasets, offering capabilities for batch processing, interactive queries, stream processing, and machine learning. 
* Apache Tika: https://tika.apache.org/
  * The Apache Tika is a Java-based toolkit that detects and extracts metadata and text from over a thousand different file types (such as PPT, XLS, and PDF). All of these file types can be parsed through a single interface, making Tika useful for search engine indexing, content analysis, translation, and much more.
* TensorFlow: https://www.tensorflow.org/
  * An open-source platform developed by Google for building and deploying machine learning models
* PyTorch: https://pytorch.org/
  * A popular open-source machine learning library known for its flexibility and speed.
* Keras: https://keras.io/
  * Keras is a high-level API for building and training deep learning models, particularly neural networks. It's known for its user-friendliness, modularity, and flexibility, making it popular for both beginners and experienced deep learning practitioners.
* Scikit-learn: https://scikit-learn.org/
  * A versatile library for machine learning algorithms and tools.

## Hardware Resources

### Consumer Grade 

* NVIDIA DGX Spark: https://www.nvidia.com/en-us/products/workstations/dgx-spark/
  * A Grace Blackwell AI supercomputer on your desk.
* TODO: This section needs more information/resources
 
## Cloud Infrastructure

* TODO: This section needs more information/resources
